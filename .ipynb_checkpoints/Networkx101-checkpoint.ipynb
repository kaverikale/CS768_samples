{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "from random import sample\n",
    "import copy\n",
    "\n",
    "filename = 'datasets/facebook.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nbr_nonnbr(G):\n",
    "    \"\"\"\n",
    "    A routine that processes a networkx graph and emits list of neighbours and non-neighbours for each node.\n",
    "    Input: NetworkX graph\n",
    "    Returns: dictionary of neighbour and non-neighbors\n",
    "    Do not use on large graphs since non-neighbour dictionary is O(n^3) storage, n: number of vertices. \n",
    "    \"\"\"\n",
    "    \n",
    "    vertex_set  = set(G.nodes())\n",
    "    vertex_list = list(vertex_set)\n",
    "    \n",
    "    nbr_dict, nonnbr_dict = {}, {}\n",
    "\n",
    "    for node in range(len(vertex_list)):\n",
    "        nbr_set = set([nbr for nbr in G[node]])\n",
    "        nonnbr_set = list(vertex_set - nbr_set)\n",
    "\n",
    "        nbr_dict[node] = nbr_set\n",
    "        nonnbr_dict[node] = nonnbr_set\n",
    "\n",
    "    return nbr_dict, nonnbr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Initialize a NetworkX graph from a file with edge list.\n",
    "        Raises Exception if provided file is not an edge list\n",
    "        \"\"\"\n",
    "        G = nx.read_edgelist(filename)\n",
    "        self.G = nx.convert_node_labels_to_integers(G)\n",
    "        self.vertex_set = set(self.G.nodes())\n",
    "        self.vertex_list = list(self.vertex_set)\n",
    "        \n",
    "    def split_train_test(self, test_fraction):\n",
    "        \"\"\"\n",
    "        Prepares the graph for training by creating a train, test graph with non-overlapping edges \n",
    "        Input test_fraction: Fraction of neighbours per node that make the test split.\n",
    "        Returns: None\n",
    "        Adds to the self test_edges_list, train_edges_list both of which are list of triples (in, out, edge-type)\n",
    "        A new graph with edges from test omitted is attached to self called G_train. \n",
    "        \"\"\"\n",
    "        assert test_fraction<=1 and test_fraction>=0\n",
    "\n",
    "        self.test_fraction = test_fraction\n",
    "        \n",
    "        nbr_dict, nonnbr_dict = find_nbr_nonnbr(self.G)\n",
    "        self.nbr_dict, self.nonnbr_dict = nbr_dict, nonnbr_dict\n",
    "        \n",
    "        per_node_train_set, per_node_test_set = {}, {}           \n",
    "        test_edges_list, train_edges_list = [], []        \n",
    "        for node in range(len(self.vertex_list)):            \n",
    "            per_node_test_set[node], per_node_train_set[node] = {}, {}\n",
    "            \n",
    "            x_nbr = int(test_fraction*len(nbr_dict[node]))\n",
    "            x_nonnbr = int(test_fraction*len(nonnbr_dict[node]))\n",
    "            \n",
    "            per_node_test_set[node]['nbr'] = sample(nbr_dict[node], x_nbr)\n",
    "            per_node_train_set[node]['nbr'] =  list(set(nbr_dict[node])\\\n",
    "                                                       - set(per_node_test_set[node]['nbr']))\n",
    "    \n",
    "            per_node_test_set[node]['nonnbr'] = sample(nonnbr_dict[node], x_nonnbr)\n",
    "            per_node_train_set[node]['nonnbr'] =  list(set(nonnbr_dict[node])\\\n",
    "                                                  - set(per_node_test_set[node]['nonnbr']))\n",
    "    \n",
    "            test_edges_per_node = [(node, x) for x in per_node_test_set[node]['nbr']]\n",
    "            test_non_edges_per_node  = [(node, x) for x in per_node_test_set[node]['nonnbr']]\n",
    "            train_edges_per_node = [(node, x) for x in per_node_train_set[node]['nbr']]\n",
    "            train_non_edges_per_node  = [(node, x) for x in per_node_train_set[node]['nonnbr']]\n",
    "            \n",
    "            test_edges_list.extend([(a, b, 1) for a, b in test_edges_per_node])\n",
    "            test_edges_list.extend([(a, b, 0) for a, b in test_non_edges_per_node])\n",
    "\n",
    "            train_edges_list.extend([(a, b, 1) for a, b in train_edges_per_node])\n",
    "            train_edges_list.extend([(a, b, 0) for a, b in train_non_edges_per_node])\n",
    "            \n",
    "        self.test_edges_list = test_edges_list         \n",
    "        self.train_edges_list = train_edges_list\n",
    "        \n",
    "        G_train =  copy.deepcopy(self.G)\n",
    "        G_train.remove_edges_from([(a, b) for (a, b, label) in test_edges_list if label==1])\n",
    "        self.G_train = G_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Fraction:  0.4\n",
      "Fraction of train edges: 0.0110\n",
      "Fraction of test edges: 0.0106\n",
      "--------------------\n",
      "Fraction:  0.3\n",
      "Fraction of train edges: 0.0110\n",
      "Fraction of test edges: 0.0104\n",
      "--------------------\n",
      "Fraction:  0.2\n",
      "Fraction of train edges: 0.0109\n",
      "Fraction of test edges: 0.0103\n",
      "--------------------\n",
      "Fraction:  0.1\n",
      "Fraction of train edges: 0.0109\n",
      "Fraction of test edges: 0.0097\n"
     ]
    }
   ],
   "source": [
    "for test_fraction in [0.4, 0.3, 0.2, 0.1]:\n",
    "    random.seed(0)\n",
    "    graph = Graph(filename)\n",
    "    graph.split_train_test(test_fraction)\n",
    "    \n",
    "    num_train_edges = len([label for (_, _, label) in graph.train_edges_list if label==1])\n",
    "    num_test_edges = len([label for (_, _, label) in graph.test_edges_list if label==1])\n",
    "    \n",
    "    print (\"--------------------\")\n",
    "    print (\"Fraction: \", test_fraction)\n",
    "    print (\"Fraction of train edges: %0.4f\" % (num_train_edges/len(graph.train_edges_list)))\n",
    "    print (\"Fraction of test edges: %0.4f\" % (num_test_edges/len(graph.test_edges_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 200 1.0133023590626364\n",
      "200 1 0.2969742043733701\n"
     ]
    }
   ],
   "source": [
    "# Use MAP, MRR to evaluate\n",
    "# Try Adamic Adar, Common Neighbor, Preferential Attachment and Katz measure \n",
    "# Ref: http://www.cs.cornell.edu/home/kleinber/link-pred.pdf\n",
    "random.seed(0)\n",
    "graph = Graph(filename)\n",
    "graph.split_train_test(0.2)\n",
    "for (u,v,p) in nx.adamic_adar_index(graph.G_train, [(10,200),(200,1)]):\n",
    "    print (u,v,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use graph.train_edges_list and graph.test_edges_list of edge, label pairs to train a logitsic regression model of scores:\n",
    "# Adamic Adar, Common Neighbor, Preferential Attachment and Katz measure to predict the edge label."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
